<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machinelles Lernen - Automatische Textanalyse :: Zertifikatskurs Data Librarian - Modul 3 - Daten analysieren und darstellen</title>
    <link>http://localhost:1313/2024-2025-ZK_Data_Librarian_Modul_3/text_analysis/index.html</link>
    <description>24.02.2025 - 02.03.2025 Machinelles Lernen - Automatische Textanalyse Zielsetzung Final möchte wir mittels maschinellen Lernens Texte automatisch analysieren. Auch hier wollen wir an einem kleinen Beispiel das Verständnis für die Grundlagen und mögliche Anwendungen entwickelt. In dem Beispiel werden wir Texte in Kategorien zuordnen und somit ein kleines automatisches Verschlagwortungswerkzeug erstellen. Dazu bauen wir auf das in der letzte Woche Erlernte zu Klassifizierugsverfahren, aber auch auf einige Punkte aus Modul 2 namentlich Term-Frequency (TF) und und Term frequency inverse document frequency (TFIDF), auf. Für die Implementation greifen wir wieder auf scikit-learn zurück.</description>
    <generator>Hugo</generator>
    <language>de-DE</language>
    <atom:link href="http://localhost:1313/2024-2025-ZK_Data_Librarian_Modul_3/text_analysis/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Text-Klassifikation</title>
      <link>http://localhost:1313/2024-2025-ZK_Data_Librarian_Modul_3/text_analysis/text_classification/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2024-2025-ZK_Data_Librarian_Modul_3/text_analysis/text_classification/index.html</guid>
      <description>Text-Klassifikations-Beispiel Das Beispiel basiert auf einem offenen Datensat von Newsgroup-Nachtrichten und orientiert sich an diesem offiziellen Tutorial von scikit-learn zur Textanalyse.&#xA;Wir nutzen Dokumente von mehreren Newsgroups und trainieren damit einen Classifier, der dann eine Zudordnung von neuen Texten auf eine dieser Gruppen durchführen kann. Sprich die Newsgroups stellen die Klassen/Tags dar, mit denen wir neue Texte klassifizieren. Wie nutzen einen einfachen Bag-of-Word-Ansatz in dem wir (normalisierte) Häufigkeit von Wörtern als Features nutzen.&#xA;In diesem Fall liegen die Daten noch nicht als Teil von scikit-learn vor, es wird aber eine Funktion angeboten, mit die Daten bezogen werden können.</description>
    </item>
    <item>
      <title>Quiz</title>
      <link>http://localhost:1313/2024-2025-ZK_Data_Librarian_Modul_3/text_analysis/quiz/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2024-2025-ZK_Data_Librarian_Modul_3/text_analysis/quiz/index.html</guid>
      <description></description>
    </item>
    <item>
      <title>Musterlösungen</title>
      <link>http://localhost:1313/2024-2025-ZK_Data_Librarian_Modul_3/text_analysis/solutions/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2024-2025-ZK_Data_Librarian_Modul_3/text_analysis/solutions/index.html</guid>
      <description>Hier ist das Jupyter Notebooks mit der Text-Klassifikation-Musterlösung (ablegen mit “Speichern unter”).</description>
    </item>
  </channel>
</rss>